{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Mini-Project BBC News\n",
    "\n",
    "For this mini project I'll be assesing the NMF (Non-Negative Matrix) module to make predictions on the category of certain articles from the BBC News using the module to set up the features according to the text entries of each article.\n",
    "\n",
    "You can find more information about the competition and sets used here [Kaggle Competition: BBC News Classification](https://www.kaggle.com/c/learn-ai-bbc/overview) and review this project on my GitHub [here](https://github.com/rorrostieta/BBC_News) you can reach out there or ping me for any clarification regarding the project.\n",
    "\n",
    "## Objective\n",
    "*\"Classify the news articles depending on their content\"* This alongside testing various models to see how each one of them perform and compare **NMF** with other supervised models.\n",
    "\n",
    "## Libraries and Resources\n",
    "For this project we're given by the competition a test sets to be evaluated I'll be exploring them to give you more context about the problem and my approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "\n",
    "For this part we can see that the set is simple, `ArticleId`, `Text` and `Category`. Since we want our approach to be an unsupervised learning model we will use the `Category` field only as tool to evaluate accuracy of the method.\n",
    "\n",
    "Let's begin!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ArticleId</th>\n",
       "      <th>Text</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1833</td>\n",
       "      <td>worldcom ex-boss launches defence lawyers defe...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>154</td>\n",
       "      <td>german business confidence slides german busin...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1101</td>\n",
       "      <td>bbc poll indicates economic gloom citizens in ...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1976</td>\n",
       "      <td>lifestyle  governs mobile choice  faster  bett...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>917</td>\n",
       "      <td>enron bosses in $168m payout eighteen former e...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ArticleId                                               Text  Category\n",
       "0       1833  worldcom ex-boss launches defence lawyers defe...  business\n",
       "1        154  german business confidence slides german busin...  business\n",
       "2       1101  bbc poll indicates economic gloom citizens in ...  business\n",
       "3       1976  lifestyle  governs mobile choice  faster  bett...      tech\n",
       "4        917  enron bosses in $168m payout eighteen former e...  business"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('.data/BBC News Train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1490 entries, 0 to 1489\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   ArticleId  1490 non-null   int64 \n",
      " 1   Text       1490 non-null   object\n",
      " 2   Category   1490 non-null   object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 35.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['Category'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['Text'].str.len().hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "business\n",
      "['from' 'be' 'have' 'are' '-' 'will' 'us' 'which' 'mr' 'but' 'an' 'had'\n",
      " 'this' 'would' 'been' 'year' 'not' 'more' 'he' 'up' 'were' 'also' 'new'\n",
      " 'than' 'their' 'firm' 'company' 'last' 'market' 'growth']\n",
      "entertainment\n",
      "['-' 'his' 'by' 'will' 'i' 'best' 'have' 'said' 'who' 'from' 'are' 'but'\n",
      " 'which' 'an' 'also' 'been' 'this' 'had' 'were' 'one' 'not' 'they' 'she'\n",
      " 'their' 'we' 'us' 'music' 'new' 'year' 'her']\n",
      "politics\n",
      "['have' 'not' 'by' 'will' 'with' 'are' 'has' 'they' 'at' 'his' '-' 'from'\n",
      " 'had' 'labour' 'government' 'an' 'we' 'this' 'i' 'been' 'were' 'people'\n",
      " 'there' 'their' '.' 'blair' 'which' 'party' 'who' 'election']\n",
      "sport\n",
      "['we' 'has' 'be' 'will' 'as' 'not' 'from' 'after' 'by' 'they' 'had'\n",
      " 'their' 'been' 'said' 'are' 'an' 'this' 'who' 'first' 't' 'against'\n",
      " 'england' '-' 'out' 'when' 'game' 'win' 'last' 'if' 'over']\n",
      "tech\n",
      "['has' 'was' 'they' 'people' 'more' 'not' 'at' 'but' 'which' 'from' 'he'\n",
      " 'can' 'this' 'or' 'their' 'an' 'its' 'about' 'mr' 'up' 'new' 'also' 'you'\n",
      " 'were' 'than' '-' 'we' 'would' 'one' 'been']\n"
     ]
    }
   ],
   "source": [
    "text_df = df.groupby('Category')['Text'].apply(','.join).reset_index()\n",
    "text_split = text_df['Text'].str.split()\n",
    "\n",
    "for i in range(len(text_split)):\n",
    "    label, counts = np.unique(text_split[i], return_counts=True)\n",
    "    idx = np.flip(counts.argsort())\n",
    "    print(text_df['Category'][i])\n",
    "    print(label[idx][20:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA Insights and Preprocessing\n",
    "From the the exploratory analysis we can see how there are 5 main categories for this data set: business, entertainment, politics, sport and tech. We have a good spread of articles each having at least more than 250 entries within their categories which helps by having a less biased data set.\n",
    "\n",
    "In terms of words er article we can see how we have a lot of articles with around 1500~ words approximately on our raw text files. Here we can see some additional outliers on articles which have more than 5000 words but I have decided not to remove them to see how my models work with the provided sets, maybe these outliers were expected and we're not meant to remove them.\n",
    "\n",
    "The last part is a small list of most frequent words and I have to say this which you might expect but we have to take into account. The most frequent words in all of the categories were the ones which are commonly used in the language such as prepositions, objects, subjects, etc. hence why I decided to print like from the top 20 to 50 to see some differenciation. Here I see how for business we begin to see words such as *market* or *company* on the top, other examples would be *game* for sport, *election* for politics and *music* for entertainment.\n",
    "\n",
    "### What about Preprocessing?\n",
    "For the project I have decided to avoid as much preprocessing as possible to see how the models could be tunned. Text preprocessing can be helpful but they add some kind of bias which I might not expect being a non-native speaker. I might remove some punctuation, accents, tildes and many more features which add context to the language.\n",
    "\n",
    "With all of this in mind, lets see how the model performs.\n",
    "\n",
    "## Text Processing Method\n",
    "The method I chose to process the text is the **TF-IDF** short for **Term Frequency-Inverse Document Frequency** I'll try to summarize the method and how it works to process the text. The first part is the term frequency which measures the amount of times a word/term appears in a document and sets a weight to that term depending on the count. On the other hand the inverse document frequency helps to reduce the weight of very common words which appear in the document, this part sets the weights of terms that appear very frequenly in many documents and the ones that occur rarely. All of this makes this method evaluate which words are specifically mentioned within documents considering that within the language there are a lot of others that support ideas but are not key to vectorize a document.\n",
    "\n",
    "This process helps to assign the text some weights which we can consider as features for our model. In this case the Non-Negative Matrix Factorization we can input this matrix.\n",
    "\n",
    "## Support Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(W):\n",
    "    sortedW = np.argsort(W)\n",
    "    n_predictions, maxValue = sortedW.shape\n",
    "    predictions = [[sortedW[i][maxValue - 1]] for i in range(n_predictions)]\n",
    "    topics = np.empty(n_predictions, dtype = np.int64)\n",
    "    for i in range(n_predictions):\n",
    "        topics[i] = predictions[i][0]\n",
    "    return topics\n",
    "\n",
    "def labels_accuracy(ytdf,yp,n=5):\n",
    "    perms = list(itertools.permutations([0, 1, 2, 3, 4]))    #create permutation list\n",
    "    best_labels = []\n",
    "    best_acc = 0 \n",
    "    current = {}\n",
    "    labels = ['business', 'tech', 'politics', 'sport', 'entertainment']\n",
    "    for perm in perms:\n",
    "        for i in range(n):\n",
    "            current[labels[i]] = perm[i]\n",
    "            if len(current) == 5:\n",
    "                conditions = [\n",
    "                    (ytdf['Category'] == current['business']),\n",
    "                    (ytdf['Category'] == current['tech']),\n",
    "                    (ytdf['Category'] == current['politics']),\n",
    "                    (ytdf['Category'] == current['sport']),\n",
    "                    (ytdf['Category'] == current['entertainment'])]\n",
    "                ytdf['test'] = ytdf['Category'].map(current)\n",
    "                current_accuracy = accuracy_score(ytdf['test'], yp)\n",
    "                if current_accuracy > best_acc: \n",
    "                    best_acc = current_accuracy\n",
    "                    best_labels = perm\n",
    "                    ytdf['best'] = ytdf['test']\n",
    "    return best_labels, best_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Preprocessing and Model Training\n",
    "Here I tested multiple parameters, here in the TF-IDF from Sklearn we can inout various ways to extract the text, whether its without any kind of puntuaction, max number of features or ngram_range which consider word combinations as features since some phrases might be unique to the category of article we're trying to extract the features from.\n",
    "\n",
    "For this scenario after using the word verctorizer method we can now input the data into the model and look for the best parameters to obtain a good training score. The key parameters I'm playing with are the beta loss and the solver hyperparameters which slightly impact the final results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(min_df=3, ngram_range=(1,2), binary=True)\n",
    "features = tfidf.fit_transform(df.Text)\n",
    "mod = NMF(n_components=5, solver='mu', beta_loss='kullback-leibler').fit(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 4, 2, 1, 3) 0.9577181208053691\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ArticleId</th>\n",
       "      <th>Text</th>\n",
       "      <th>Category</th>\n",
       "      <th>test</th>\n",
       "      <th>best</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1833</td>\n",
       "      <td>worldcom ex-boss launches defence lawyers defe...</td>\n",
       "      <td>business</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>154</td>\n",
       "      <td>german business confidence slides german busin...</td>\n",
       "      <td>business</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1101</td>\n",
       "      <td>bbc poll indicates economic gloom citizens in ...</td>\n",
       "      <td>business</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1976</td>\n",
       "      <td>lifestyle  governs mobile choice  faster  bett...</td>\n",
       "      <td>tech</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>917</td>\n",
       "      <td>enron bosses in $168m payout eighteen former e...</td>\n",
       "      <td>business</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ArticleId                                               Text  Category  \\\n",
       "0       1833  worldcom ex-boss launches defence lawyers defe...  business   \n",
       "1        154  german business confidence slides german busin...  business   \n",
       "2       1101  bbc poll indicates economic gloom citizens in ...  business   \n",
       "3       1976  lifestyle  governs mobile choice  faster  bett...      tech   \n",
       "4        917  enron bosses in $168m payout eighteen former e...  business   \n",
       "\n",
       "   test  best  \n",
       "0     4     0  \n",
       "1     4     0  \n",
       "2     4     0  \n",
       "3     3     4  \n",
       "4     4     0  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = predict(mod.transform(features))\n",
    "label_order, accuracy = labels_accuracy(df, y )\n",
    "print(label_order, accuracy)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Testing\n",
    "Ater achieving a good model fit we then need to see how the model performs on the provided test data. First we need to set up the test data the same way the train was in order for the model to be interpreted, in our case since the competition provides separate solution and tests we merge them for the function we had previously to work on the data and check the accuracy correcly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('.data/BBC News Test.csv')\n",
    "sol = pd.read_csv('.data/BBC News Sample Solution.csv')\n",
    "df_test = test_data.merge(sol, on='ArticleId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2, 4, 0, 3) 0.24489795918367346\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ArticleId</th>\n",
       "      <th>Text</th>\n",
       "      <th>Category</th>\n",
       "      <th>test</th>\n",
       "      <th>best</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1018</td>\n",
       "      <td>qpr keeper day heads for preston queens park r...</td>\n",
       "      <td>sport</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1319</td>\n",
       "      <td>software watching while you work software that...</td>\n",
       "      <td>tech</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1138</td>\n",
       "      <td>d arcy injury adds to ireland woe gordon d arc...</td>\n",
       "      <td>business</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>459</td>\n",
       "      <td>india s reliance family feud heats up the ongo...</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1020</td>\n",
       "      <td>boro suffer morrison injury blow middlesbrough...</td>\n",
       "      <td>politics</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ArticleId                                               Text  \\\n",
       "0       1018  qpr keeper day heads for preston queens park r...   \n",
       "1       1319  software watching while you work software that...   \n",
       "2       1138  d arcy injury adds to ireland woe gordon d arc...   \n",
       "3        459  india s reliance family feud heats up the ongo...   \n",
       "4       1020  boro suffer morrison injury blow middlesbrough...   \n",
       "\n",
       "        Category  test  best  \n",
       "0          sport     1     0  \n",
       "1           tech     3     2  \n",
       "2       business     4     1  \n",
       "3  entertainment     0     0  \n",
       "4       politics     2     4  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_test = tfidf.transform(test_data.Text)\n",
    "y_test = predict(mod.transform(features_test))\n",
    "label_order_test, accuracy_test = labels_accuracy(df_test, y_test )\n",
    "print(label_order_test, accuracy_test)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NMF Results\n",
    "Looking into our results we can see how despite us achieving a 0.95 accuracy on the training data we only have a 0.24 accuracy on our test data which we could say the model does not perform that well. This might be involved with how we're vectorizing the text features or tunning the model to the point where it overfits on the training sets and does not perform as well on the test set.\n",
    "\n",
    "In the future I might need to use other methods of text vectorizing and see how it performs on this exact NMF model, to discard any issues with how the vectorizing is being done.\n",
    "\n",
    "# Supervised Model Comparison\n",
    "For this project I'm going to see how our NMF model fares against a supervised model since we're provided the labels in the competition.\n",
    "\n",
    "For this part I have selected an ensemble method (Random Forest) and a support vector machine (SVC) to see their performance and compare them in a final analysis to define which method was the most adequate one. I'll be using the same feature matrix we obtained with the TF-IDF method just to be fair to these methods and have a better comparison on the performance of both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = tfidf.fit_transform(df.Text).toarray()\n",
    "labels = df.Category\n",
    "test_features = tfidf.transform(df_test.Text).toarray()\n",
    "test_labels = df_test.Category\n",
    "\n",
    "RF_mod = RandomForestClassifier(n_estimators=150, max_depth=4).fit(features, labels)\n",
    "SVC_mod = SVC().fit(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier: 0.8711409395973154\n",
      "Support Vector Machine (Classifier): 1.0\n"
     ]
    }
   ],
   "source": [
    "RF_pred_labels = RF_mod.predict(features)\n",
    "SV_pred_labels = SVC_mod.predict(features)\n",
    "\n",
    "ac_RF = accuracy_score(labels, RF_pred_labels)\n",
    "ac_SV = accuracy_score(labels, SV_pred_labels)\n",
    "\n",
    "print('Random Forest Classifier:', ac_RF)\n",
    "print('Support Vector Machine (Classifier):', ac_SV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier: 0.19591836734693877\n",
      "Support Vector Machine (Classifier): 0.18639455782312925\n"
     ]
    }
   ],
   "source": [
    "RFtest_pred_labels = RF_mod.predict(test_features)\n",
    "SVtest_pred_labels = SVC_mod.predict(test_features)\n",
    "\n",
    "ac_RF = accuracy_score(test_labels, RFtest_pred_labels)\n",
    "ac_SV = accuracy_score(test_labels, SVtest_pred_labels)\n",
    "\n",
    "print('Random Forest Classifier:', ac_RF)\n",
    "print('Support Vector Machine (Classifier):', ac_SV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "When comparing the supervised models agasint the unsupervised ones we see two key insights:\n",
    "* Some supervised models can overfit much more easily\n",
    "* Unsupervised models seem more flexible when test data is added\n",
    "\n",
    "With those two core ideas we can see how an SVC model overfits on the train data having a accuracy of 1 but when test data is added to the equation we obtain the lowest accuracy of all of the models analyzed. Either way the supervised methods did not return better results compared to the unsupervised which leads us to say that with the available information for this text classification problem a unsupervised model works better than the supervised ones.\n",
    "\n",
    "## Conclusion\n",
    "To conclude this project I'll sumarrize into the following bullet points:\n",
    "* Text vectorization matters\n",
    "\n",
    "How we decide to translate text features to vectors/matrices is key since these are the inputs to our models, changing the vectorizing method might drastically impact the final result of the model.\n",
    "\n",
    "* Problem Context Matters\n",
    "\n",
    "Knowing the type the problem is key to define if we can do suprvised or unsupervised learning. In our case unsupervised showed better performance but this could change if the nature of the problem is different, text analysis and classification might be a good case where it might be better to not know the outcome whereas a problem where we have quantitative attributes a supervised model might return better results, we need to test all the tools available to see which one is the best for out case since there is not a one size fits all solution.\n",
    "\n",
    "This would be the key points I'd like to share with you, if you have any feedback or comments feel free to reach out on GitHub or other platforms to see how this work can be improved."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fa5e5e9a487e2dd76c7ea7823608b3e5576beb764152fabbf69ac7563ac3923b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
